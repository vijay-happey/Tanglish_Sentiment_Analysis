{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bharaj/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import fileinput\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import datetime\n",
    "import sys\n",
    "from tqdm  import tqdm\n",
    "tqdm.pandas()\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "a0600af701d2d03c2d3e7f952dbeac1cac9a6b13",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "34b8a2b0038c21b865256563d376b0b5faaa7e4c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect(tokens):\n",
    "    return [t for t in tokens if t in valid_forms]\n",
    "    \n",
    "def replace_blank(tokens):\n",
    "    return [blank if t in valid_forms else t for t in tokens]\n",
    "\n",
    "def create_windows(tokens, window_size=3):\n",
    "    X = []\n",
    "    for i, word in enumerate(tokens):\n",
    "        if word == blank:\n",
    "            window = tokens[i-window_size:i] + tokens[i+1:i+window_size+1]\n",
    "            window = ' '.join(window)\n",
    "            X.append(window)    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "bcf71adc4358539a3d158ee5f97daf4683d90365",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = open(\"../input/internet_archive_scifi_v3.txt\",\"r\")\n",
    "a = f1.read()\n",
    "a = re.sub('[\\n]', '', a)\n",
    "tokens = wordpunct_tokenize(a)\n",
    "y = detect(tokens)\n",
    "tokens = replace_blank(tokens)\n",
    "X = create_windows(tokens)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "eaa001a351805a031cfc44928333fab9304eae5b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"Text\"] = X\n",
    "df[\"Label\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "5d39979b41d504a25bff4303e41aba5de29a9456"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Publisher Editor IF published bi -</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in this magazine fiction . Any</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to actual persons coincidental . #</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. The title selected after much</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the theory it indicative of the</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Text Label\n",
       "0  Publisher Editor IF published bi -    is\n",
       "1      in this magazine fiction . Any   are\n",
       "2  to actual persons coincidental . #    is\n",
       "3     . The title selected after much   was\n",
       "4     the theory it indicative of the    is"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "ba9e53d73830a70df82bda50ce6339ca8f7d205c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>am</th>\n",
       "      <th>are</th>\n",
       "      <th>be</th>\n",
       "      <th>been</th>\n",
       "      <th>being</th>\n",
       "      <th>is</th>\n",
       "      <th>was</th>\n",
       "      <th>were</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Publisher Editor IF published bi -</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in this magazine fiction . Any</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to actual persons coincidental . #</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. The title selected after much</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the theory it indicative of the</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Text  am  are  be  ...   being  is  was  were\n",
       "0  Publisher Editor IF published bi -   0    0   0  ...       0   1    0     0\n",
       "1      in this magazine fiction . Any   0    1   0  ...       0   0    0     0\n",
       "2  to actual persons coincidental . #   0    0   0  ...       0   1    0     0\n",
       "3     . The title selected after much   0    0   0  ...       0   0    1     0\n",
       "4     the theory it indicative of the   0    0   0  ...       0   1    0     0\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = pd.get_dummies(df[\"Label\"])\n",
    "df.drop(['Label'],axis=1,inplace=True)\n",
    "df = pd.concat([df,one_hot],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "ba3ca115ffafaf35f1eeedc1449b836ac1fa8a60",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df[:200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "4d92865168b510a57a218078f18c85d71883a903",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1[\"Text\"].values, df1.drop(['Text'],axis=1).values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "90b59bf2fe0b277e3e6bd4961e80fdb460132675",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 20000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(sequences, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "a66ac1534c360c1443d9b41e6377555e0d810fda",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(sequences, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "69419594e347fb579921b93b2657f00b585ad094",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000, 100, input_length=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(8, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "4321b53974828dde8364d4867978a309f77d4eab",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "df58cce943e21007beb4a3fb9715691e38f26408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144000 samples, validate on 16000 samples\n",
      "Epoch 1/10\n",
      "144000/144000 [==============================] - 9s 63us/step - loss: 1.2964 - acc: 0.5442 - val_loss: 0.8224 - val_acc: 0.6970\n",
      "Epoch 2/10\n",
      "144000/144000 [==============================] - 6s 42us/step - loss: 0.7231 - acc: 0.7306 - val_loss: 0.7121 - val_acc: 0.7288\n",
      "Epoch 3/10\n",
      "144000/144000 [==============================] - 6s 42us/step - loss: 0.6077 - acc: 0.7703 - val_loss: 0.6938 - val_acc: 0.7380\n",
      "Epoch 4/10\n",
      "144000/144000 [==============================] - 6s 42us/step - loss: 0.5328 - acc: 0.7999 - val_loss: 0.7015 - val_acc: 0.7392\n",
      "Epoch 5/10\n",
      "144000/144000 [==============================] - 6s 44us/step - loss: 0.4699 - acc: 0.8248 - val_loss: 0.7154 - val_acc: 0.7394\n",
      "Epoch 6/10\n",
      "144000/144000 [==============================] - 7s 47us/step - loss: 0.4172 - acc: 0.8458 - val_loss: 0.7408 - val_acc: 0.7341\n",
      "Epoch 7/10\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.3745 - acc: 0.8622 - val_loss: 0.7854 - val_acc: 0.7323\n",
      "Epoch 8/10\n",
      "144000/144000 [==============================] - 6s 43us/step - loss: 0.3398 - acc: 0.8756 - val_loss: 0.8090 - val_acc: 0.7268\n",
      "Epoch 9/10\n",
      "144000/144000 [==============================] - 6s 42us/step - loss: 0.3074 - acc: 0.8878 - val_loss: 0.8501 - val_acc: 0.7234\n",
      "Epoch 10/10\n",
      "144000/144000 [==============================] - 6s 42us/step - loss: 0.2796 - acc: 0.8988 - val_loss: 0.8865 - val_acc: 0.7253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3aca61ee48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "                    batch_size=1024,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "8ff81a21315b716a94d0d7d5966371dbc05526a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 50us/step\n",
      "Test accuracy: 0.722975\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test,\n",
    "                       batch_size=256, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "658dc1479c287153b7f6a58487eeaf2692c88ada",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "4958e35b19fff351c2736be1c147b3cf3ba2b9c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.55      0.56       486\n",
      "           1       0.55      0.50      0.53      2889\n",
      "           2       0.92      0.95      0.93      6128\n",
      "           3       0.95      0.93      0.94      3336\n",
      "           4       0.41      0.32      0.36       765\n",
      "           5       0.52      0.46      0.49      5911\n",
      "           6       0.75      0.79      0.77     15788\n",
      "           7       0.59      0.59      0.59      4697\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     40000\n",
      "   macro avg       0.66      0.64      0.65     40000\n",
      "weighted avg       0.72      0.72      0.72     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test,axis=1),np.argmax(preds,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "f06e533fa0af9d8eccb9c0efb06813a9aff0e494"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "64f2c3a0c296d5bb724b405d18a8df438db444da"
   },
   "source": [
    "# BERT implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "02a6443556928bda3f2527b7d803361de3e8e518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-01-13 18:00:08--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.193.128, 2a00:1450:400b:c01::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.193.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 407727028 (389M) [application/zip]\n",
      "Saving to: ‘uncased_L-12_H-768_A-12.zip.2’\n",
      "\n",
      "uncased_L-12_H-768_ 100%[===================>] 388.84M  22.4MB/s    in 18s     \n",
      "\n",
      "2020-01-13 18:00:26 (22.2 MB/s) - ‘uncased_L-12_H-768_A-12.zip.2’ saved [407727028/407727028]\n",
      "\n",
      "--2020-01-13 18:00:27--  https://raw.githubusercontent.com/google-research/bert/master/modeling.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 37922 (37K) [text/plain]\n",
      "Saving to: ‘modeling.py.3’\n",
      "\n",
      "modeling.py.3       100%[===================>]  37.03K  --.-KB/s    in 0.004s  \n",
      "\n",
      "2020-01-13 18:00:27 (9.99 MB/s) - ‘modeling.py.3’ saved [37922/37922]\n",
      "\n",
      "--2020-01-13 18:00:27--  https://raw.githubusercontent.com/google-research/bert/master/optimization.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6258 (6.1K) [text/plain]\n",
      "Saving to: ‘optimization.py.3’\n",
      "\n",
      "optimization.py.3   100%[===================>]   6.11K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-01-13 18:00:27 (70.1 MB/s) - ‘optimization.py.3’ saved [6258/6258]\n",
      "\n",
      "--2020-01-13 18:00:27--  https://raw.githubusercontent.com/google-research/bert/master/run_classifier.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 34783 (34K) [text/plain]\n",
      "Saving to: ‘run_classifier.py.3’\n",
      "\n",
      "run_classifier.py.3 100%[===================>]  33.97K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2020-01-13 18:00:28 (10.7 MB/s) - ‘run_classifier.py.3’ saved [34783/34783]\n",
      "\n",
      "--2020-01-13 18:00:28--  https://raw.githubusercontent.com/google-research/bert/master/tokenization.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12257 (12K) [text/plain]\n",
      "Saving to: ‘tokenization.py.3’\n",
      "\n",
      "tokenization.py.3   100%[===================>]  11.97K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-01-13 18:00:28 (86.8 MB/s) - ‘tokenization.py.3’ saved [12257/12257]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/optimization.py \n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/run_classifier.py \n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/tokenization.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-01-13 18:01:03--  https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.193.128, 2a00:1450:400b:c01::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.193.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 662903077 (632M) [application/zip]\n",
      "Saving to: ‘multi_cased_L-12_H-768_A-12.zip.1’\n",
      "\n",
      "multi_cased_L-12_H- 100%[===================>] 632.19M  13.2MB/s    in 49s     \n",
      "\n",
      "2020-01-13 18:01:53 (12.9 MB/s) - ‘multi_cased_L-12_H-768_A-12.zip.1’ saved [662903077/662903077]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "2b1a537730f8d6a59633a18e18443e422a3c7281"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0115 09:01:18.860536 139863621216000 deprecation_wrapper.py:119] From /home/bharaj/papers/code-mix/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import modeling\n",
    "import optimization\n",
    "import run_classifier\n",
    "import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6739, 2)\n",
      "                                                Text  Label\n",
      "0   Ichayan fans pinne mmade ettan fansm ivde oru...      4\n",
      "1             Tovi 🥰 Best Wishes From #Kunjikka Fans      3\n",
      "2   Urutty koll .nallavanaaya unniyaya saiju kuru...      4\n",
      "3   Pls support me pls       My channel subscribe...      3\n",
      "4     Kalki super hit akum enn Bonny parayan paranju      2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('whole_mal.tsv',sep='\\t',names=['category','text'])\n",
    "print(df.shape)\n",
    "\n",
    "y=df['category']\n",
    "df2 = pd.DataFrame()\n",
    "df2[\"Text\"] = df[\"text\"]\n",
    "df2[\"Label\"] = LabelEncoder().fit_transform(y)\n",
    "#df2 = df2[:200000]\n",
    "print(df2.head())\n",
    "X_train, X_test, y_train, y_test = train_test_split(df2[\"Text\"].values, df2[\"Label\"].values, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "1aa95f622d1b59645a9e22c2e6d5d2a5f29a2a50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Model output directory: model_folder/outputs-n\n",
      ">>  BERT pretrained directory: model_folder/multi_cased_L-12_H-768_A-12\n"
     ]
    }
   ],
   "source": [
    "folder = 'model_folder'\n",
    "with zipfile.ZipFile(\"multi_cased_L-12_H-768_A-12.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(folder)\n",
    "BERT_MODEL = 'multi_cased_L-12_H-768_A-12'\n",
    "BERT_PRETRAINED_DIR = f'{folder}/multi_cased_L-12_H-768_A-12'\n",
    "OUTPUT_DIR = f'{folder}/outputs-n'\n",
    "print(f'>> Model output directory: {OUTPUT_DIR}')\n",
    "print(f'>>  BERT pretrained directory: {BERT_PRETRAINED_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "20541f718c86fed1131409bcc9ee7736d3ec88ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Model output directory: model_folder/outputs\n",
      ">>  BERT pretrained directory: model_folder/uncased_L-12_H-768_A-12\n"
     ]
    }
   ],
   "source": [
    "BERT_MODEL = 'uncased_L-12_H-768_A-12'\n",
    "BERT_PRETRAINED_DIR = f'{folder}/uncased_L-12_H-768_A-12'\n",
    "OUTPUT_DIR = f'{folder}/outputs'\n",
    "print(f'>> Model output directory: {OUTPUT_DIR}')\n",
    "print(f'>>  BERT pretrained directory: {BERT_PRETRAINED_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "725094e6c9961e294f575672d4ee81449d745b1b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ichayan fans pinne mmade ettan fansm ivde oru...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tovi 🥰 Best Wishes From #Kunjikka Fans</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Urutty koll .nallavanaaya unniyaya saiju kuru...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pls support me pls       My channel subscribe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalki super hit akum enn Bonny parayan paranju</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0   Ichayan fans pinne mmade ettan fansm ivde oru...      4\n",
       "1             Tovi 🥰 Best Wishes From #Kunjikka Fans      3\n",
       "2   Urutty koll .nallavanaaya unniyaya saiju kuru...      4\n",
       "3   Pls support me pls       My channel subscribe...      3\n",
       "4     Kalki super hit akum enn Bonny parayan paranju      2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df2 = pd.DataFrame()\n",
    "# df2[\"Text\"] = df[\"text\"]\n",
    "# df2[\"Label\"] = LabelEncoder().fit_transform(y)\n",
    "# df2 = df2[:200000]\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "7990d9f6cdd2960ebfd61c40c58d3c1acb7d18b6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(df2[\"Text\"].values, df2[\"Label\"].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "1a128c3f38ab69351e34f87977cec04d9d6c9189"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0113 18:03:14.965779 140559672616704 deprecation_wrapper.py:119] From /home/bharaj/papers/code-mix/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0113 18:03:16.591481 140559672616704 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0113 18:03:16.594780 140559672616704 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd605eef0d0>) includes params argument, but params are not passed to Estimator.\n",
      "W0113 18:03:16.597678 140559672616704 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.\n"
     ]
    }
   ],
   "source": [
    "def create_examples(lines, set_type, labels=None):\n",
    "#Generate data for the BERT model\n",
    "    guid = f'{set_type}'\n",
    "    examples = []\n",
    "    if guid == 'train':\n",
    "        for line, label in zip(lines, labels):\n",
    "            text_a = line\n",
    "            label = str(label)\n",
    "            examples.append(\n",
    "              run_classifier.InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "    else:\n",
    "        for line in lines:\n",
    "            text_a = line\n",
    "            label = '0'\n",
    "            examples.append(\n",
    "              run_classifier.InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "    return examples\n",
    "\n",
    "# Model Hyper Parameters\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "EVAL_BATCH_SIZE = 8\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_TRAIN_EPOCHS = 3.0\n",
    "WARMUP_PROPORTION = 0.1\n",
    "MAX_SEQ_LENGTH = 50\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 100000 #if you wish to finetune a model on a larger dataset, use larger interval\n",
    "# each checpoint weights about 1,5gb\n",
    "ITERATIONS_PER_LOOP = 100000\n",
    "NUM_TPU_CORES = 8\n",
    "VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
    "CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
    "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
    "DO_LOWER_CASE = BERT_MODEL.startswith('uncased')\n",
    "\n",
    "label_list = [str(num) for num in range(8)]\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=DO_LOWER_CASE)\n",
    "train_examples = create_examples(X_train, 'train', labels=y_train)\n",
    "\n",
    "tpu_cluster_resolver = None #Since training will happen on GPU, we won't need a cluster resolver\n",
    "#TPUEstimator also supports training on CPU and GPU. You don't need to define a separate tf.estimator.Estimator.\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
    "        num_shards=NUM_TPU_CORES,\n",
    "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
    "\n",
    "num_train_steps = int(\n",
    "    len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "model_fn = run_classifier.model_fn_builder(\n",
    "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
    "    num_labels=len(label_list),\n",
    "    init_checkpoint=INIT_CHECKPOINT,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    use_tpu=False, #If False training will fall on CPU or GPU, depending on what is available  \n",
    "    use_one_hot_embeddings=True)\n",
    "\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=False, #If False training will fall on CPU or GPU, depending on what is available \n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    eval_batch_size=EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3cb95e4f486c7743add1039f996f501d07109fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0113 18:03:43.242447 140559672616704 deprecation_wrapper.py:119] From /home/bharaj/papers/code-mix/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0113 18:03:45.204365 140559672616704 deprecation.py:323] From /home/bharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Started training at 2020-01-13 18:03:45.185022 \n",
      "  Num examples = 5391\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0113 18:03:47.120745 140559672616704 deprecation_wrapper.py:119] From /home/bharaj/papers/code-mix/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0113 18:03:47.124726 140559672616704 deprecation_wrapper.py:119] From /home/bharaj/papers/code-mix/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0113 18:03:47.162734 140559672616704 deprecation_wrapper.py:119] From /home/bharaj/papers/code-mix/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "W0113 18:03:47.211796 140559672616704 deprecation.py:506] From /home/bharaj/papers/code-mix/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0113 18:03:47.235380 140559672616704 deprecation.py:323] From /home/bharaj/papers/code-mix/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0113 18:03:51.243477 140559672616704 deprecation_wrapper.py:119] From /home/bharaj/papers/code-mix/run_classifier.py:647: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W0113 18:03:51.250007 140559672616704 deprecation_wrapper.py:119] From /home/bharaj/papers/code-mix/run_classifier.py:661: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "W0113 18:03:52.534084 140559672616704 deprecation_wrapper.py:119] From /home/bharaj/papers/code-mix/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "W0113 18:03:52.537686 140559672616704 deprecation_wrapper.py:119] From /home/bharaj/papers/code-mix/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n",
      "W0113 18:03:52.548060 140559672616704 deprecation.py:323] From /home/bharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "W0113 18:03:52.837559 140559672616704 deprecation.py:323] From /home/bharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "print('Please wait...')\n",
    "train_features = run_classifier.convert_examples_to_features(\n",
    "    train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "print('>> Started training at {} '.format(datetime.datetime.now()))\n",
    "print('  Num examples = {}'.format(len(train_examples)))\n",
    "print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
    "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
    "train_input_fn = run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=True)\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print('>> Finished training at {}'.format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ed42f193d4586b10b58a65ea06c3d51385160bb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn_builder(features, seq_length, is_training, drop_remainder):\n",
    "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
    "\n",
    "  all_input_ids = []\n",
    "  all_input_mask = []\n",
    "  all_segment_ids = []\n",
    "  all_label_ids = []\n",
    "\n",
    "  for feature in features:\n",
    "    all_input_ids.append(feature.input_ids)\n",
    "    all_input_mask.append(feature.input_mask)\n",
    "    all_segment_ids.append(feature.segment_ids)\n",
    "    all_label_ids.append(feature.label_id)\n",
    "\n",
    "  def input_fn(params):\n",
    "    \"\"\"The actual input function.\"\"\"\n",
    "    print(params)\n",
    "    batch_size = 500\n",
    "\n",
    "    num_examples = len(features)\n",
    "\n",
    "    d = tf.data.Dataset.from_tensor_slices({\n",
    "        \"input_ids\":\n",
    "            tf.constant(\n",
    "                all_input_ids, shape=[num_examples, seq_length],\n",
    "                dtype=tf.int32),\n",
    "        \"input_mask\":\n",
    "            tf.constant(\n",
    "                all_input_mask,\n",
    "                shape=[num_examples, seq_length],\n",
    "                dtype=tf.int32),\n",
    "        \"segment_ids\":\n",
    "            tf.constant(\n",
    "                all_segment_ids,\n",
    "                shape=[num_examples, seq_length],\n",
    "                dtype=tf.int32),\n",
    "        \"label_ids\":\n",
    "            tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
    "    })\n",
    "\n",
    "    if is_training:\n",
    "      d = d.repeat()\n",
    "      d = d.shuffle(buffer_size=100)\n",
    "\n",
    "    d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
    "    return d\n",
    "\n",
    "  return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ddf519b690697635cbd3b47d2ee875feb94fd822",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_examples = create_examples(X_test, 'test')\n",
    "\n",
    "predict_features = run_classifier.convert_examples_to_features(\n",
    "    predict_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "predict_input_fn = input_fn_builder(\n",
    "    features=predict_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)\n",
    "\n",
    "result = estimator.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb9635b3771ecc148b7dc7a2bf4f5de6a8173445",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for prediction in result:\n",
    "      preds.append(np.argmax(prediction['probabilities']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f5cc9b9374f73ce94a04b9448e6807976cd89ec0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "de003a2788e27d334232bd515572d73304192fe5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy of BERT is:\",accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1586642280c06b07158651391f2e80b7756a7a3c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "9d77113dca6782b19458f391d1d48769ad1e487a",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
